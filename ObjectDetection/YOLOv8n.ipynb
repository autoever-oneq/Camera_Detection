{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxwCPV23qQhx"
      },
      "source": [
        "# 설치 & 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNvhLxS2gqmr"
      },
      "source": [
        "## pip install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgpJNG28Zp9F",
        "outputId": "83194af4-0216-4600-eab1-57c495459912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.196 --quiet\n",
        "!pip install roboflow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKBFRxkvguQC"
      },
      "source": [
        "# 런타임 환경 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnB8M0R7KMnc"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c5IBoCgybqFo"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "from IPython.display import Image\n",
        "from roboflow import Roboflow\n",
        "import ultralytics\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l466TFvUKRSR"
      },
      "source": [
        "## Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgzByLdjKeHN",
        "outputId": "8a4cf916-87c7-4a59-dd90-cff7ff356b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.196 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 33.2/112.6 GB disk)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "display.clear_output()\n",
        "ultralytics.checks()\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwaB7WxXj_ip"
      },
      "source": [
        "# 간이 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2_4o-BjJiwbG"
      },
      "outputs": [],
      "source": [
        "#!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True\n",
        "#Image(filename='runs/detect/predict/dog.jpeg', height=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "ae44fFyjcbGS"
      },
      "outputs": [],
      "source": [
        "#!mkdir {HOME}/datasets\n",
        "#%cd {HOME}/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIv6AlOGzdEt"
      },
      "source": [
        "# Model Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hSvHP_k5BFi"
      },
      "outputs": [],
      "source": [
        "# api_key는 계정마다 다름\n",
        "# 여기 밑에 Roboflow에서 복사한 내용 붙여넣으면 됩니다\n",
        "rf = Roboflow(api_key=\"\")\n",
        "project = rf.workspace(\"yolov8n-shyng\").project(\"one-q\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vr_X51Zk6U83"
      },
      "outputs": [],
      "source": [
        "# CLI 방식 Train\n",
        "# train 이후 나온 weight에 이어서 재학습 시키려면 yolov8n.pt를 best.pt로 바꾸면 되지 않을까 싶음\n",
        "!yolo task=detect mode=train model=yolov8n.pt data={dataset.location}/data.yaml epochs=30 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5ImaTrqWcE__"
      },
      "outputs": [],
      "source": [
        "# CLI 방식 Predict\n",
        "!yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt conf=0.7 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1nhFcufLmbP"
      },
      "source": [
        "# 코드 방식 train(현재 실행 x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "l-Y4IcaHqpt0",
        "outputId": "09c06796-4723-4383-efda-cf31d71dae59"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Load a COCO-pretrained YOLOv8n model\\nmodel = YOLO(\"yolov8n.pt\")\\n\\n# Display model information (optional)\\nmodel.info()\\n\\n# Train the model on the COCO8 example dataset for 100 epochs\\nresults = model.train(data=\"{dataset.location}/data.yaml\", epochs=50, imgsz=640)\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code 방식\n",
        "\"\"\"\n",
        "# Load a COCO-pretrained YOLOv8n model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()\n",
        "\n",
        "# Train the model on the COCO8 example dataset for 100 epochs\n",
        "results = model.train(data=\"{dataset.location}/data.yaml\", epochs=50, imgsz=640)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0siJlrCC0Q3Z",
        "outputId": "4f410d65-5176-4390-fc41-fe7222c88ae0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nresult = model(\\'runs/detect/predict/dog.jpeg\\')\\n\\n# Process results list\\nfor result in results:\\n    boxes = result.boxes  # Boxes object for bounding box outputs\\n    masks = result.masks  # Masks object for segmentation masks outputs\\n    keypoints = result.keypoints  # Keypoints object for pose outputs\\n    probs = result.probs  # Probs object for classification outputs\\n    obb = result.obb  # Oriented boxes object for OBB outputs\\n    result.show()  # display to screen\\n    result.save(filename=\"result.jpg\")  # save to disk\\n'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "result = model('runs/detect/predict/dog.jpeg')\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    result.save(filename=\"result.jpg\")  # save to disk\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mk9-aMrGgN0L",
        "outputId": "c0b17b19-ba6a-4a21-b3a0-5ba029414ad6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport glob\\n\\n# path & slicing 수정 필요\\nfor image_path in glob.glob(\\'/content/runs/detect/predict4/*.jpg\\')[:5]:\\n  display(Image(filename=image_path, width=640))\\n  print(\"\\n\")\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import glob\n",
        "\n",
        "# path & slicing 수정 필요\n",
        "for image_path in glob.glob('/content/runs/detect/predict4/*.jpg')[:5]:\n",
        "  display(Image(filename=image_path, width=640))\n",
        "  print(\"\\n\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qAG_-80qJJf"
      },
      "source": [
        "# 참고 자료"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeDJ5FJOi4KG"
      },
      "source": [
        "https://autoever-oneq.atlassian.net/wiki/spaces/ADP/pages/12124230/YOLO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
