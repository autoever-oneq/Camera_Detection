{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ì„¤ì¹˜ & í™•ì¸"
      ],
      "metadata": {
        "id": "vxwCPV23qQhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pip install"
      ],
      "metadata": {
        "id": "UNvhLxS2gqmr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TgpJNG28Zp9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3dee02-875d-4483-d509-8a0a771ef7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.196 --quiet\n",
        "!pip install roboflow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ëŸ°íƒ€ì„ í™˜ê²½ í™•ì¸"
      ],
      "metadata": {
        "id": "IKBFRxkvguQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "wnB8M0R7KMnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "from IPython.display import Image\n",
        "from roboflow import Roboflow\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import os"
      ],
      "metadata": {
        "id": "c5IBoCgybqFo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version"
      ],
      "metadata": {
        "id": "l466TFvUKRSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display.clear_output()\n",
        "ultralytics.checks()\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgzByLdjKeHN",
        "outputId": "36b5292b-dc7c-4b8f-8a94-634dd8dc6f51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.196 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.2/112.6 GB disk)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê°„ì´ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "CwaB7WxXj_ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True\n",
        "#Image(filename='runs/detect/predict/dog.jpeg', height=600)"
      ],
      "metadata": {
        "id": "2_4o-BjJiwbG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir {HOME}/datasets\n",
        "#%cd {HOME}/datasets"
      ],
      "metadata": {
        "id": "ae44fFyjcbGS",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Run"
      ],
      "metadata": {
        "id": "aIv6AlOGzdEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# api_keyëŠ” ê³„ì •ë§ˆë‹¤ ë‹¤ë¦„\n",
        "rf = Roboflow(api_key=\"wNo4QrXGVHMuGz8nVoBq\")\n",
        "project = rf.workspace(\"yolov8n-shyng\").project(\"one-q\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "8hSvHP_k5BFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53927dc-e35d-4e3d-ceb1-09216225bd33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in ONE-Q-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27501/27501 [00:00<00:00, 37156.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to ONE-Q-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3030/3030 [00:00<00:00, 4072.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### ----- CLI ë°©ì‹ ----- ###\n",
        "# Train\n",
        "# train ì´í›„ ë‚˜ì˜¨ weightì— ì´ì–´ì„œ ì¬í•™ìŠµ ì‹œí‚¤ë ¤ë©´ yolov8n.ptë¥¼ best.ptë¡œ ë°”ê¾¸ë©´ ë˜ì§€ ì•Šì„ê¹Œ ì‹¶ìŒ\n",
        "!yolo task=detect mode=train model=yolov8n.pt data={dataset.location}/data.yaml epochs=30 imgsz=640 plots=True\n",
        "\n",
        "# Predict\n",
        "!yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt conf=0.7 source={dataset.location}/test/images save=True\n",
        "\"\"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vr_X51Zk6U83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ----- Code ë°©ì‹ ----- ###\n",
        "# Train\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "model.info()\n",
        "model.train(data=f\"{dataset.location}/data.yaml\", epochs=30, imgsz=640)  # \"./datasets/ONE-Q-1/data.yaml\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLqiU9wkpalT",
        "outputId": "d78cb3da-7c11-4739-e77e-84bcced93cdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 113MB/s]\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "YOLOv8n summary: 225 layers, 3157200 parameters, 0 gradients, 8.9 GFLOPs\n",
            "New https://pypi.org/project/ultralytics/8.3.74 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.196 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/ONE-Q-1/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 20.7MB/s]\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/ONE-Q-1/train/labels... 1355 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1355/1355 [00:00<00:00, 2305.22it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/ONE-Q-1/train/labels.cache\n",
            "A new version of Albumentations is available: '2.0.4' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "Got processor for bboxes, but no transform to process it.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ONE-Q-1/valid/labels... 77 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:00<00:00, 1958.36it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/ONE-Q-1/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.24G      0.864      1.877      1.032         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:27<00:00,  3.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]\n",
            "                   all         77         77      0.953      0.892      0.982      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.16G     0.8516      1.232      1.027         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:25<00:00,  3.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]\n",
            "                   all         77         77      0.782      0.968      0.915      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.16G     0.8723      1.027      1.035         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.13it/s]\n",
            "                   all         77         77       0.82      0.895      0.891      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.16G     0.8341      0.837      1.018         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.24it/s]\n",
            "                   all         77         77      0.966      0.756      0.823      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.16G     0.8077     0.7492      1.012         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:26<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.12it/s]\n",
            "                   all         77         77      0.997      0.996      0.995      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.16G     0.8038     0.6587     0.9988         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.43it/s]\n",
            "                   all         77         77      0.973      0.991      0.993      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.16G     0.7882     0.6132      1.001         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:25<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]\n",
            "                   all         77         77      0.997          1      0.995       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.16G     0.7508     0.5739      0.987         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:29<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.23it/s]\n",
            "                   all         77         77      0.994          1      0.995       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.16G     0.7499     0.5461     0.9888         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:27<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.51it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.16G     0.7166     0.5113     0.9698         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.10it/s]\n",
            "                   all         77         77      0.995          1      0.995      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.16G     0.7204       0.51     0.9727         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.16G     0.6956     0.4795     0.9642         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:27<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.44it/s]\n",
            "                   all         77         77      0.994          1      0.995      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50      2.16G     0.7091     0.4822     0.9737         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]\n",
            "                   all         77         77      0.995          1      0.995      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.16G     0.6792     0.4525     0.9525         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.99it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.16G     0.6732     0.4568     0.9624         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.46it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.16G     0.6658     0.4505     0.9537         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.46it/s]\n",
            "                   all         77         77      0.995          1      0.995      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.16G     0.6897     0.4475     0.9476         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.31it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.16G     0.6567     0.4232     0.9575         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.22it/s]\n",
            "                   all         77         77      0.998      0.996      0.995      0.761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.16G     0.6585     0.4326     0.9473         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:26<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.47it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.16G     0.6199      0.402     0.9356         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.16G     0.6431      0.411     0.9481         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.08it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.16G     0.6347     0.3925     0.9422         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.16it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.16G     0.6234     0.3931     0.9304         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.07it/s]\n",
            "                   all         77         77      0.998          1      0.995       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.16G     0.6067     0.3776     0.9272         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.07it/s]\n",
            "                   all         77         77      0.995          1      0.995      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.16G     0.5977     0.3797     0.9279         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.38it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.16G     0.6172     0.3767     0.9329         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:25<00:00,  3.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.16G      0.594     0.3649       0.93         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.34it/s]\n",
            "                   all         77         77      0.998          1      0.995      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.16G     0.5995     0.3604     0.9261         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]\n",
            "                   all         77         77      0.998          1      0.995       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.16G     0.5779     0.3514     0.9195         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]\n",
            "                   all         77         77      0.998          1      0.995      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.16G     0.5615     0.3406     0.9211         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.20it/s]\n",
            "                   all         77         77      0.995          1      0.995      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.16G     0.5763     0.3548     0.9201         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.16G     0.5536     0.3355     0.9093         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.61it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.16G     0.5611     0.3304     0.9151         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.81it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.16G     0.5554     0.3409     0.9076         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:25<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.38it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.16G     0.5526     0.3371     0.9091         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.40it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.16G     0.5418     0.3286     0.9095         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:25<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.786\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.16G     0.5493     0.3313     0.9168         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]\n",
            "                   all         77         77      0.996          1      0.995       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.16G      0.537      0.316     0.8992         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.16G     0.5248     0.3023     0.9014         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:23<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.16G     0.5277     0.3121     0.9046         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.799\n",
            "Closing dataloader mosaic\n",
            "Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "Got processor for bboxes, but no transform to process it.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.16G     0.4771     0.2566     0.8633         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:26<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]\n",
            "                   all         77         77      0.997          1      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.16G     0.4665     0.2536     0.8636         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:23<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.62it/s]\n",
            "                   all         77         77      0.995          1      0.995      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.16G     0.4613     0.2529     0.8538         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.18it/s]\n",
            "                   all         77         77      0.997          1      0.995       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.16G     0.4509     0.2469     0.8616         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:23<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.59it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.16G     0.4474     0.2452     0.8503         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:23<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.92it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.16G     0.4462     0.2427     0.8474         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:22<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n",
            "                   all         77         77      0.997          1      0.995       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.16G     0.4321     0.2325     0.8493         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:23<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.80it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.16G     0.4267     0.2305     0.8457         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.16G       0.42     0.2268     0.8474         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:23<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.71it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.16G     0.4119      0.223     0.8453         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:24<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.27it/s]\n",
            "                   all         77         77      0.997          1      0.995      0.849\n",
            "\n",
            "50 epochs completed in 0.368 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.196 ğŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]\n",
            "                   all         77         77      0.996          1      0.995      0.859\n",
            "         Rear-Side Car         77         17      0.994          1      0.995      0.856\n",
            "         Side-Side Car         77         60      0.999          1      0.995      0.863\n",
            "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b1d13f57b50>\n",
              "fitness: 0.8727297746060612\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.85552,     0.86277])\n",
              "names: {0: 'Rear-Side Car', 1: 'Side-Side Car'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9964846297361457, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.995, 'metrics/mAP50-95(B)': 0.8591441940067346, 'fitness': 0.8727297746060612}\n",
              "save_dir: PosixPath('runs/detect/train')\n",
              "speed: {'preprocess': 0.23142083898767246, 'inference': 2.455599896319501, 'loss': 0.000582112894429789, 'postprocess': 1.9091104532217051}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test(predict)\n",
        "model = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
        "testImgDir = (f\"{dataset.location}/test/images\") # \"./ONE-Q-1/test/images\"\n",
        "\n",
        "print(testImgDir)\n",
        "for img in os.listdir(testImgDir):\n",
        "  imgName = f\"{testImgDir}/{img}\"\n",
        "  #print(imgName)\n",
        "  results = model.predict(source=imgName, save=True)\n",
        "  print(results[0].boxes.xyxy, results[0].boxes.xyxyn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih0Yjmqx1Q45",
        "outputId": "3736b805-aa1d-417e-d112-f7c6149e92c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2456_jpg.rf.aefdf9e9fbeef6f38ee880a9a4aef52b.jpg: 640x640 1 Side-Side Car, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ONE-Q-1/test/images\n",
            "tensor([[209.3929, 312.6387, 325.0471, 377.0923]], device='cuda:0') "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2161_jpg.rf.1410cd3b67615510ed23e6f3a7429d3c.jpg: 640x640 1 Rear-Side Car, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2192_jpg.rf.5a7147d555d997caa756e2e1d318e84c.jpg: 640x640 1 Rear-Side Car, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2697_jpg.rf.33ad26045ceef3ec97fdc9d8e6a00cd9.jpg: 640x640 1 Side-Side Car, 7.7ms\n",
            "Speed: 2.6ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2117_jpg.rf.818afde35b7a1db43610c0d8bb3128b2.jpg: 640x640 1 Rear-Side Car, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2431_jpg.rf.8b6e3199135f4e0a46110b97955193ca.jpg: 640x640 1 Side-Side Car, 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2646_jpg.rf.a818347d8da0f262e2ed449c029fafe5.jpg: 640x640 1 Side-Side Car, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3272, 0.4885, 0.5079, 0.5892]], device='cuda:0')\n",
            "tensor([[266.1475, 289.3024, 367.9430, 382.0964]], device='cuda:0') tensor([[0.4159, 0.4520, 0.5749, 0.5970]], device='cuda:0')\n",
            "tensor([[510.3773, 320.0257, 640.0000, 429.5943]], device='cuda:0') tensor([[0.7975, 0.5000, 1.0000, 0.6712]], device='cuda:0')\n",
            "tensor([[536.5342, 373.2285, 639.8870, 443.8339]], device='cuda:0') tensor([[0.8383, 0.5832, 0.9998, 0.6935]], device='cuda:0')\n",
            "tensor([[411.7986, 231.2410, 640.0000, 435.3103]], device='cuda:0') tensor([[0.6434, 0.3613, 1.0000, 0.6802]], device='cuda:0')\n",
            "tensor([[550.1877, 364.8870, 639.9614, 447.4935]], device='cuda:0') tensor([[0.8597, 0.5701, 0.9999, 0.6992]], device='cuda:0')\n",
            "tensor([[488.9350, 370.9969, 639.2852, 464.8199]], device='cuda:0') tensor([[0.7640, 0.5797, 0.9989, 0.7263]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2465_jpg.rf.58863efe7488f435bfdbd071ba0bf2f1.jpg: 640x640 1 Side-Side Car, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2308_jpg.rf.b1e43fdd1638ae2ab79dbed3e840d26b.jpg: 640x640 1 Side-Side Car, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2193_jpg.rf.f7ca777878dbc8e7176bd6fbde953a86.jpg: 640x640 1 Rear-Side Car, 7.5ms\n",
            "Speed: 2.6ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2696_jpg.rf.1b4fd988c1473e791a3ea1b055700816.jpg: 640x640 1 Side-Side Car, 7.6ms\n",
            "Speed: 2.7ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2455_jpg.rf.63c65c11f296089e4fa37a96393fc1c4.jpg: 640x640 1 Side-Side Car, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2680_jpg.rf.99e676bc76095026db1fb7f24b239c85.jpg: 640x640 1 Side-Side Car, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2254_jpg.rf.ba9193d0306a577ff94a33ab8dca4dfc.jpg: 640x640 1 Side-Side Car, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 96.7990, 315.5109, 222.3109, 381.8545]], device='cuda:0') tensor([[0.1512, 0.4930, 0.3474, 0.5966]], device='cuda:0')\n",
            "tensor([[393.0396, 347.9245, 613.3168, 465.0578]], device='cuda:0') tensor([[0.6141, 0.5436, 0.9583, 0.7267]], device='cuda:0')\n",
            "tensor([[502.3206, 318.2781, 639.9210, 425.2280]], device='cuda:0') tensor([[0.7849, 0.4973, 0.9999, 0.6644]], device='cuda:0')\n",
            "tensor([[  0.0000, 320.0357, 130.1265, 415.4189]], device='cuda:0') tensor([[0.0000, 0.5001, 0.2033, 0.6491]], device='cuda:0')\n",
            "tensor([[218.8862, 313.5732, 333.6967, 377.6157]], device='cuda:0') tensor([[0.3420, 0.4900, 0.5214, 0.5900]], device='cuda:0')\n",
            "tensor([[ 86.0218, 290.1866, 231.9947, 373.4460]], device='cuda:0') tensor([[0.1344, 0.4534, 0.3625, 0.5835]], device='cuda:0')\n",
            "tensor([[292.1901, 299.2778, 612.9611, 482.8514]], device='cuda:0')"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2259_jpg.rf.fefc1f431b6cc57b8eed4221640da351.jpg: 640x640 1 Side-Side Car, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2470_jpg.rf.272c15cffca772654c9f508aff65cd84.jpg: 640x640 1 Side-Side Car, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2457_jpg.rf.055f1265b2f5792e8969604caf031f10.jpg: 640x640 1 Side-Side Car, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2468_jpg.rf.28863783dc35a9366ccdfabfd9ae8e32.jpg: 640x640 1 Side-Side Car, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2690_jpg.rf.f80b247a8ac5945280b55aab66ce5ed4.jpg: 640x640 1 Side-Side Car, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2118_jpg.rf.e4511ab6a31165f30694451e08f0f0f5.jpg: 640x640 1 Rear-Side Car, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2462_jpg.rf.45c271f761d93cae9cc3c3c50d0757a9.jpg: 640x640 1 Side-Side Car, 7.8ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tensor([[0.4565, 0.4676, 0.9578, 0.7545]], device='cuda:0')\n",
            "tensor([[171.0922, 289.4000, 497.3945, 477.6249]], device='cuda:0') tensor([[0.2673, 0.4522, 0.7772, 0.7463]], device='cuda:0')\n",
            "tensor([[ 47.3748, 304.8665, 180.5643, 375.8355]], device='cuda:0') tensor([[0.0740, 0.4764, 0.2821, 0.5872]], device='cuda:0')\n",
            "tensor([[212.3635, 309.6711, 326.0030, 374.3488]], device='cuda:0') tensor([[0.3318, 0.4839, 0.5094, 0.5849]], device='cuda:0')\n",
            "tensor([[ 58.0788, 306.5330, 191.8698, 375.0250]], device='cuda:0') tensor([[0.0907, 0.4790, 0.2998, 0.5860]], device='cuda:0')\n",
            "tensor([[1.0373e-01, 3.1935e+02, 1.6163e+02, 4.1099e+02]], device='cuda:0') tensor([[1.6208e-04, 4.9899e-01, 2.5255e-01, 6.4218e-01]], device='cuda:0')\n",
            "tensor([[419.1808, 223.3290, 640.0000, 425.9654]], device='cuda:0') tensor([[0.6550, 0.3490, 1.0000, 0.6656]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Speed: 2.4ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2667_jpg.rf.038214792769efcb3ab2620a753adef8.jpg: 640x640 1 Side-Side Car, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2486_jpg.rf.7378aac49e1af5861bc26c4f056416c3.jpg: 640x640 1 Side-Side Car, 8.3ms\n",
            "Speed: 2.7ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2444_jpg.rf.74b6124b6023e90b5a1eebbc0cb51e9a.jpg: 640x640 1 Side-Side Car, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2732_jpg.rf.9507a084059d278abe745edce450cdd7.jpg: 640x640 1 Side-Side Car, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2458_jpg.rf.4b0668e39b5d6662613e44eee3faa37b.jpg: 640x640 1 Side-Side Car, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2173_jpg.rf.6101f600a1d47aae7f807d21b2751126.jpg: 640x640 1 Rear-Side Car, 8.9ms\n",
            "Speed: 2.6ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[105.0277, 322.8180, 227.1279, 385.7001]], device='cuda:0') tensor([[0.1641, 0.5044, 0.3549, 0.6027]], device='cuda:0')\n",
            "tensor([[226.9656, 267.7675, 358.7352, 347.6687]], device='cuda:0') tensor([[0.3546, 0.4184, 0.5605, 0.5432]], device='cuda:0')\n",
            "tensor([[554.5182, 357.4289, 640.0000, 436.2349]], device='cuda:0') tensor([[0.8664, 0.5585, 1.0000, 0.6816]], device='cuda:0')\n",
            "tensor([[388.7769, 319.4027, 507.7540, 383.4643]], device='cuda:0') tensor([[0.6075, 0.4991, 0.7934, 0.5992]], device='cuda:0')\n",
            "tensor([[2.1098e-01, 2.7403e+02, 1.0660e+02, 3.4210e+02]], device='cuda:0') tensor([[3.2965e-04, 4.2818e-01, 1.6657e-01, 5.3453e-01]], device='cuda:0')\n",
            "tensor([[223.1503, 313.7101, 334.7001, 379.2121]], device='cuda:0') tensor([[0.3487, 0.4902, 0.5230, 0.5925]], device='cuda:0')\n",
            "tensor([[131.9616, 262.9716, 243.5851, 359.9824]], device='cuda:0') tensor([[0.2062, 0.4109, 0.3806, 0.5625]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2442_jpg.rf.ed774aff6ad1128bedd4004a06c82557.jpg: 640x640 1 Side-Side Car, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2715_jpg.rf.44dc0e2dfdc06f77c3001248361074f0.jpg: 640x640 1 Side-Side Car, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2692_jpg.rf.ddbc1ad64ec0b7ee621b4fcbdc57d380.jpg: 640x640 1 Side-Side Car, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2448_jpg.rf.aa38f9d0b9a57e5140a0793e61463a83.jpg: 640x640 1 Side-Side Car, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2175_jpg.rf.4336f9db5a0b220268f81b48a69a543a.jpg: 640x640 1 Rear-Side Car, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2709_jpg.rf.f9c0ef9b13ea085199ee4741b7b7bc55.jpg: 640x640 1 Side-Side Car, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[408.9394, 322.7443, 527.4858, 386.9628]], device='cuda:0') tensor([[0.6390, 0.5043, 0.8242, 0.6046]], device='cuda:0')\n",
            "tensor([[254.6123, 312.9494, 349.5579, 368.8031]], device='cuda:0') tensor([[0.3978, 0.4890, 0.5462, 0.5763]], device='cuda:0')\n",
            "tensor([[  0.0000, 319.8101, 153.1270, 410.5982]], device='cuda:0') tensor([[0.0000, 0.4997, 0.2393, 0.6416]], device='cuda:0')\n",
            "tensor([[318.7468, 323.6638, 431.3208, 384.8663]], device='cuda:0') tensor([[0.4980, 0.5057, 0.6739, 0.6014]], device='cuda:0')\n",
            "tensor([[124.2332, 264.7823, 237.7612, 360.2715]], device='cuda:0') tensor([[0.1941, 0.4137, 0.3715, 0.5629]], device='cuda:0')\n",
            "tensor([[366.8008, 328.8338, 466.9945, 390.0992]], device='cuda:0') tensor([[0.5731, 0.5138, 0.7297, 0.6095]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2451_jpg.rf.832ace4043ab5e5ad781252541540f30.jpg: 640x640 1 Side-Side Car, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2685_jpg.rf.676a207c0108ca85e17214f6655e6091.jpg: 640x640 1 Side-Side Car, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2172_jpg.rf.49bcb32a1d69ef0b4f77cf6ce54bf8e6.jpg: 640x640 1 Rear-Side Car, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2437_jpg.rf.fea399306e5cf0b83a8117e21488091b.jpg: 640x640 1 Side-Side Car, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2436_jpg.rf.300e4eb5d7c07476131c8adde68c324f.jpg: 640x640 1 Side-Side Car, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2133_jpg.rf.9acc9c9b53387c70a0cca0751e486689.jpg: 640x640 1 Rear-Side Car, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[282.4835, 323.0823, 393.2871, 384.1455]], device='cuda:0') tensor([[0.4414, 0.5048, 0.6145, 0.6002]], device='cuda:0')\n",
            "tensor([[ 37.4058, 304.5811, 192.1382, 392.7479]], device='cuda:0') tensor([[0.0584, 0.4759, 0.3002, 0.6137]], device='cuda:0')\n",
            "tensor([[141.2486, 263.4176, 252.9342, 359.4562]], device='cuda:0') tensor([[0.2207, 0.4116, 0.3952, 0.5617]], device='cuda:0')\n",
            "tensor([[488.7506, 338.9528, 619.2134, 411.0210]], device='cuda:0') tensor([[0.7637, 0.5296, 0.9675, 0.6422]], device='cuda:0')\n",
            "tensor([[497.5008, 347.2946, 631.1764, 418.3049]], device='cuda:0') tensor([[0.7773, 0.5426, 0.9862, 0.6536]], device='cuda:0')\n",
            "tensor([[ 88.8245, 250.6062, 358.5421, 470.5928]], device='cuda:0') tensor([[0.1388, 0.3916, 0.5602, 0.7353]], device='cuda:0')"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2480_jpg.rf.df19a31958cc812f9025f4c166587a57.jpg: 640x640 1 Side-Side Car, 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2453_jpg.rf.cb90bcefabb5f10c3ebd84944ab71db2.jpg: 640x640 1 Side-Side Car, 14.1ms\n",
            "Speed: 4.8ms preprocess, 14.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2450_jpg.rf.c68c79f74d0735ea5a65e15bd99f72c4.jpg: 640x640 1 Side-Side Car, 14.0ms\n",
            "Speed: 4.2ms preprocess, 14.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2164_jpg.rf.90cf0f29ae765909a49c536244811f98.jpg: 640x640 1 Rear-Side Car, 14.0ms\n",
            "Speed: 3.3ms preprocess, 14.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tensor([[  0.0000, 343.2671, 100.4514, 434.0999]], device='cuda:0') tensor([[0.0000, 0.5364, 0.1570, 0.6783]], device='cuda:0')\n",
            "tensor([[239.7052, 312.5656, 351.3419, 376.3804]], device='cuda:0') tensor([[0.3745, 0.4884, 0.5490, 0.5881]], device='cuda:0')\n",
            "tensor([[294.1041, 324.7484, 406.0354, 385.5235]], device='cuda:0') tensor([[0.4595, 0.5074, 0.6344, 0.6024]], device='cuda:0')\n",
            "tensor([[214.0051, 274.0137, 318.8015, 368.6421]], device='cuda:0') tensor([[0.3344, 0.4281, 0.4981, 0.5760]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2469_jpg.rf.d692308ed07e56b11a9f0416b883906f.jpg: 640x640 1 Side-Side Car, 15.1ms\n",
            "Speed: 5.2ms preprocess, 15.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2440_jpg.rf.7f5ba1a73c400e20479938f8db73e6e8.jpg: 640x640 1 Side-Side Car, 13.6ms\n",
            "Speed: 4.5ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2190_jpg.rf.d89fb2b9a7de3687950c4572702cfd31.jpg: 640x640 1 Rear-Side Car, 16.4ms\n",
            "Speed: 4.2ms preprocess, 16.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2707_jpg.rf.f0722d9f5db873daff0b62f5ce881459.jpg: 640x640 1 Side-Side Car, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2463_jpg.rf.ccf4a4b9768c3ba5ee512ace99e674f9.jpg: 640x640 1 Side-Side Car, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 50.7563, 306.0466, 185.9821, 377.2455]], device='cuda:0') tensor([[0.0793, 0.4782, 0.2906, 0.5894]], device='cuda:0')\n",
            "tensor([[441.1817, 328.9128, 566.3774, 396.4136]], device='cuda:0') tensor([[0.6893, 0.5139, 0.8850, 0.6194]], device='cuda:0')\n",
            "tensor([[  8.5484, 326.0563, 143.2520, 428.8232]], device='cuda:0') tensor([[0.0134, 0.5095, 0.2238, 0.6700]], device='cuda:0')\n",
            "tensor([[398.9711, 336.1216, 504.5151, 401.6804]], device='cuda:0') tensor([[0.6234, 0.5252, 0.7883, 0.6276]], device='cuda:0')\n",
            "tensor([[ 96.9526, 321.2991, 220.8409, 384.8672]], device='cuda:0') tensor([[0.1515, 0.5020, 0.3451, 0.6014]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2695_jpg.rf.f69ed6fd73bed41429607eea7e850722.jpg: 640x640 1 Side-Side Car, 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2122_jpg.rf.f677c0ded724c5fa6ce79df831776c2b.jpg: 640x640 1 Rear-Side Car, 11.8ms\n",
            "Speed: 5.0ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2664_jpg.rf.3fd544e3705edede6a6c9acfe9d5a5b0.jpg: 640x640 1 Side-Side Car, 17.3ms\n",
            "Speed: 6.5ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2724_jpg.rf.308d560bb14ab8f5b20e9e6a35ed8f57.jpg: 640x640 1 Side-Side Car, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2475_jpg.rf.081df84f91840e78695290f419b2fa26.jpg: 640x640 1 Side-Side Car, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.0000, 322.3901, 134.0246, 416.3273]], device='cuda:0') tensor([[0.0000, 0.5037, 0.2094, 0.6505]], device='cuda:0')\n",
            "tensor([[332.9927, 270.5361, 605.4974, 477.5771]], device='cuda:0') tensor([[0.5203, 0.4227, 0.9461, 0.7462]], device='cuda:0')\n",
            "tensor([[222.0376, 279.7508, 350.2800, 360.3460]], device='cuda:0') tensor([[0.3469, 0.4371, 0.5473, 0.5630]], device='cuda:0')\n",
            "tensor([[ 61.6165, 264.6353, 173.7883, 328.3881]], device='cuda:0') tensor([[0.0963, 0.4135, 0.2715, 0.5131]], device='cuda:0')\n",
            "tensor([[  5.8659, 315.5114, 147.8583, 394.6057]], device='cuda:0') tensor([[0.0092, 0.4930, 0.2310, 0.6166]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2255_jpg.rf.8e8592afe5161310a1395eb5ecdb630f.jpg: 640x640 1 Side-Side Car, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2701_jpg.rf.f669cf7a316c1a21ae3f8d7f7dfe96f1.jpg: 640x640 1 Side-Side Car, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2178_jpg.rf.8f7be1b81ffdf46131bf6cf29949544e.jpg: 640x640 1 Rear-Side Car, 11.8ms\n",
            "Speed: 2.8ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2452_jpg.rf.9c9aeabfc1c89248d7905c7827b222e4.jpg: 640x640 1 Side-Side Car, 21.1ms\n",
            "Speed: 2.6ms preprocess, 21.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2488_jpg.rf.8284a9999ebb381041c7e640285d6360.jpg: 640x640 1 Side-Side Car, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2483_jpg.rf.7071bd5c65d55b54dbb23ee492797e96.jpg: 640x640 1 Side-Side Car, 10.3ms\n",
            "Speed: 3.9ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[267.1134, 291.0292, 582.8344, 477.0367]], device='cuda:0') tensor([[0.4174, 0.4547, 0.9107, 0.7454]], device='cuda:0')\n",
            "tensor([[531.8020, 367.9722, 639.8359, 439.8385]], device='cuda:0') tensor([[0.8309, 0.5750, 0.9997, 0.6872]], device='cuda:0')\n",
            "tensor([[ 60.5233, 291.4330, 183.7359, 392.3365]], device='cuda:0') tensor([[0.0946, 0.4554, 0.2871, 0.6130]], device='cuda:0')\n",
            "tensor([[254.9733, 325.0075, 367.7267, 386.4160]], device='cuda:0') tensor([[0.3984, 0.5078, 0.5746, 0.6038]], device='cuda:0')\n",
            "tensor([[542.9911, 353.2094, 640.0000, 435.1460]], device='cuda:0') tensor([[0.8484, 0.5519, 1.0000, 0.6799]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2449_jpg.rf.d1328e03fbf62a1428d6d898b125c58c.jpg: 640x640 1 Side-Side Car, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2460_jpg.rf.4a5bf93f25819234ba93eb30da829b3a.jpg: 640x640 1 Side-Side Car, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2471_jpg.rf.65fcc52486ef66ad2944ad5c5fcf5ff9.jpg: 640x640 1 Side-Side Car, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2097_jpg.rf.9112e1188a9e4824adbcaa37b164a659.jpg: 640x640 1 Rear-Side Car, 14.5ms\n",
            "Speed: 4.7ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2153_jpg.rf.cded3c8cdbfebd260a3c1fc67617cfac.jpg: 640x640 1 Rear-Side Car, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.0000, 345.5598, 100.3961, 431.4575]], device='cuda:0') tensor([[0.0000, 0.5399, 0.1569, 0.6742]], device='cuda:0')\n",
            "tensor([[300.0035, 321.8588, 412.2518, 382.1699]], device='cuda:0') tensor([[0.4688, 0.5029, 0.6441, 0.5971]], device='cuda:0')\n",
            "tensor([[144.5793, 322.9384, 264.1520, 386.9963]], device='cuda:0') tensor([[0.2259, 0.5046, 0.4127, 0.6047]], device='cuda:0')\n",
            "tensor([[ 24.4660, 303.1183, 162.7704, 376.4228]], device='cuda:0') tensor([[0.0382, 0.4736, 0.2543, 0.5882]], device='cuda:0')\n",
            "tensor([[321.3915, 254.2798, 382.6182, 304.5081]], device='cuda:0') tensor([[0.5022, 0.3973, 0.5978, 0.4758]], device='cuda:0')\n",
            "tensor([[357.1503, 314.8096, 466.2673, 415.1672]], device='cuda:0') tensor([[0.5580, 0.4919, 0.7285, 0.6487]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2459_jpg.rf.81daea62db5b96c4bb75f4d3ed154531.jpg: 640x640 1 Side-Side Car, 14.6ms\n",
            "Speed: 4.5ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2721_jpg.rf.fa4f3844c79b2350c734befc00b8e79e.jpg: 640x640 1 Side-Side Car, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2467_jpg.rf.73787bce9744ec22828b258754644b1e.jpg: 640x640 1 Side-Side Car, 11.5ms\n",
            "Speed: 2.7ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2198_jpg.rf.749753f86a2432fc68d192d704c593b7.jpg: 640x640 1 Rear-Side Car, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2698_jpg.rf.d1aae1e1c74cf9900df7dfb321831ada.jpg: 640x640 1 Side-Side Car, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2443_jpg.rf.15291987c6f31fa1d451c71511395b14.jpg: 640x640 1 Side-Side Car, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2713_jpg.rf.666bdce212ad2f7f02b16128b9f51102.jpg: 640x640 1 Side-Side Car, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[213.2464, 324.9033, 327.1712, 390.7338]], device='cuda:0') tensor([[0.3332, 0.5077, 0.5112, 0.6105]], device='cuda:0')\n",
            "tensor([[ 88.9130, 280.2081, 200.8085, 345.3384]], device='cuda:0') tensor([[0.1389, 0.4378, 0.3138, 0.5396]], device='cuda:0')\n",
            "tensor([[ 58.4187, 306.7461, 192.1424, 375.7931]], device='cuda:0') tensor([[0.0913, 0.4793, 0.3002, 0.5872]], device='cuda:0')\n",
            "tensor([[532.1067, 307.7556, 639.9253, 408.9022]], device='cuda:0') tensor([[0.8314, 0.4809, 0.9999, 0.6389]], device='cuda:0')\n",
            "tensor([[536.0267, 373.0266, 639.8805, 443.7717]], device='cuda:0') tensor([[0.8375, 0.5829, 0.9998, 0.6934]], device='cuda:0')\n",
            "tensor([[401.6978, 314.1886, 519.5593, 379.5908]], device='cuda:0') tensor([[0.6277, 0.4909, 0.8118, 0.5931]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2156_jpg.rf.ea963303ad817c0afa6cf96674eebe12.jpg: 640x640 1 Rear-Side Car, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2464_jpg.rf.5ada4efd38734c472424c669398e4658.jpg: 640x640 1 Side-Side Car, 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2439_jpg.rf.3f0c3811c01a9f4fe383520ac7487a8a.jpg: 640x640 1 Side-Side Car, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2479_jpg.rf.6130085f2c814a54d510324e7969dc55.jpg: 640x640 1 Side-Side Car, 11.9ms\n",
            "Speed: 2.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2474_jpg.rf.29b6b230409e12d29a7dcfe46e9bc637.jpg: 640x640 1 Side-Side Car, 7.4ms\n",
            "Speed: 1.7ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "\n",
            "image 1/1 /content/ONE-Q-1/test/images/IMG_2300_jpg.rf.a318ba6ac549f7a7312263621fd71c22.jpg: 640x640 1 Side-Side Car, 7.3ms\n",
            "Speed: 1.7ms preprocess, 7.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[294.4409, 307.3523, 390.9099, 362.5840]], device='cuda:0') tensor([[0.4601, 0.4802, 0.6108, 0.5665]], device='cuda:0')\n",
            "tensor([[332.7789, 328.8412, 436.3965, 428.8747]], device='cuda:0') tensor([[0.5200, 0.5138, 0.6819, 0.6701]], device='cuda:0')\n",
            "tensor([[ 91.0448, 317.3845, 216.8578, 383.5588]], device='cuda:0') tensor([[0.1423, 0.4959, 0.3388, 0.5993]], device='cuda:0')\n",
            "tensor([[461.8644, 332.5467, 586.8721, 401.2894]], device='cuda:0') tensor([[0.7217, 0.5196, 0.9170, 0.6270]], device='cuda:0')\n",
            "tensor([[  0.0000, 343.8544,  98.6722, 435.3816]], device='cuda:0') tensor([[0.0000, 0.5373, 0.1542, 0.6803]], device='cuda:0')\n",
            "tensor([[2.5940e-03, 3.0491e+02, 1.1240e+02, 4.0283e+02]], device='cuda:0') tensor([[4.0531e-06, 4.7643e-01, 1.7562e-01, 6.2942e-01]], device='cuda:0')\n",
            "tensor([[460.9243, 323.6203, 640.0000, 448.6697]], device='cuda:0') tensor([[0.7202, 0.5057, 1.0000, 0.7010]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì½”ë“œ ë°©ì‹ train(í˜„ì¬ ì‹¤í–‰ x)"
      ],
      "metadata": {
        "id": "N1nhFcufLmbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "result = model('runs/detect/predict/dog.jpeg')\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    result.save(filename=\"result.jpg\")  # save to disk\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0siJlrCC0Q3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4f410d65-5176-4390-fc41-fe7222c88ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nresult = model(\\'runs/detect/predict/dog.jpeg\\')\\n\\n# Process results list\\nfor result in results:\\n    boxes = result.boxes  # Boxes object for bounding box outputs\\n    masks = result.masks  # Masks object for segmentation masks outputs\\n    keypoints = result.keypoints  # Keypoints object for pose outputs\\n    probs = result.probs  # Probs object for classification outputs\\n    obb = result.obb  # Oriented boxes object for OBB outputs\\n    result.show()  # display to screen\\n    result.save(filename=\"result.jpg\")  # save to disk\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import glob\n",
        "\n",
        "# path & slicing ìˆ˜ì • í•„ìš”\n",
        "for image_path in glob.glob('/content/runs/detect/predict4/*.jpg')[:5]:\n",
        "  display(Image(filename=image_path, width=640))\n",
        "  print(\"\\n\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mk9-aMrGgN0L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c0b17b19-ba6a-4a21-b3a0-5ba029414ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport glob\\n\\n# path & slicing ìˆ˜ì • í•„ìš”\\nfor image_path in glob.glob(\\'/content/runs/detect/predict4/*.jpg\\')[:5]:\\n  display(Image(filename=image_path, width=640))\\n  print(\"\\n\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì°¸ê³  ìë£Œ"
      ],
      "metadata": {
        "id": "6qAG_-80qJJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://autoever-oneq.atlassian.net/wiki/spaces/ADP/pages/12124230/YOLO"
      ],
      "metadata": {
        "id": "PeDJ5FJOi4KG"
      }
    }
  ]
}